{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Table Expressions Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common table expressions provide a temporary result set that can be used in a query.  They are useful for operating on table data then querying from that resulting information.  CTEs also can simplify the readability of complex SQL queries.  In this lab we will write several CTEs to calculate a dataset's average, then select the inputs that are above that average.  We will also use CTEs to delete duplicate rows from our table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "1.  Become comfortable writing common table expressions with the `WITH [CTE_name] AS ()` clause\n",
    "2.  Write a CTE to calculate the average of a dataset and return the table inputs that are above that average\n",
    "3.  Use a CTE to delete duplicate inputs from the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Store Sales Reprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work from the same set of Records-R-Sweet store sales data from the Window Functions lab.  Recall that Records-R-Sweet had a store in five places: Manhattan, Brooklyn, Washington, Houston, and London.  What if Records-R-Sweet wishes to open a second store in London?  We cannot refer to London twice in our `sales` table, so we have replaced the \"location\" column with a \"location_id\" that refers to a separate `locations` table.  Each location now has a unique identifier, its id, and an address.  The two tables are featured below:\n",
    "\n",
    "`locations`:\n",
    "\n",
    "|city      |address         |\n",
    "|----------|----------------|\n",
    "|Manhattan |350 5th Avenue  |\n",
    "|Brooklyn  |1904 Surf Avenue|\n",
    "|Washington|2 15th St NW    |\n",
    "|Houston   |3 NRG Pkwy      |\n",
    "|London    |Fulham Rd SW6   |\n",
    "\n",
    "\n",
    "`sales`:\n",
    "\n",
    "|sale_id|date_of_sale|location_id|amount|\n",
    "|-------|------------|-----------|------|\n",
    "|1      |'2018-04-21'|1          |50    |\n",
    "|2      |'2018-04-21'|1          |40    |\n",
    "|3      |'2018-04-22'|1          |60    |\n",
    "|4      |'2018-04-22'|1          |30    |\n",
    "|5      |'2018-04-22'|1          |30    |\n",
    "|6      |'2018-04-23'|1          |30    |\n",
    "|7      |'2018-04-23'|1          |80    |\n",
    "|8      |'2018-04-21'|2          |90    |\n",
    "|9      |'2018-04-22'|2          |80    |\n",
    "|10     |'2018-04-22'|2          |80    |\n",
    "|11     |'2018-04-22'|2          |70    |\n",
    "|12     |'2018-04-23'|2          |90    |\n",
    "|13     |'2018-04-23'|2          |80    |\n",
    "|14     |'2018-04-21'|3          |20    |\n",
    "|15     |'2018-04-21'|3          |30    |\n",
    "|16     |'2018-04-21'|3          |20    |\n",
    "|17     |'2018-04-22'|3          |30    |\n",
    "|18     |'2018-04-22'|3          |40    |\n",
    "|19     |'2018-04-23'|3          |20    |\n",
    "|20     |'2018-04-21'|4          |25    |\n",
    "|21     |'2018-04-22'|4          |30    |\n",
    "|22     |'2018-04-23'|4          |35    |\n",
    "|23     |'2018-04-23'|4          |25    |\n",
    "|24     |'2018-04-21'|5          |100   |\n",
    "|25     |'2018-04-22'|5          |50    |\n",
    "|26     |'2018-04-22'|5          |75    |\n",
    "|27     |'2018-04-23'|5          |45    |\n",
    "|8      |'2018-04-21'|2          |90    |\n",
    "|8      |'2018-04-21'|2          |90    |\n",
    "|8      |'2018-04-21'|2          |90    |\n",
    "|16     |'2018-04-21'|3          |20    |\n",
    "|24     |'2018-04-21'|5          |100   |\n",
    "|24     |'2018-04-21'|5          |100   |\n",
    "|24     |'2018-04-21'|5          |100   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Calculate the average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of the lab, write your queries inside the `part_1_ctes.py` file.  Your queries should be wrapped inside triple quotes so they can take up multiple lines.\n",
    "\n",
    "* `use_cte_to_determine_average_sale`\n",
    "\n",
    "First, write a CTE called `average_sales` that calculates the average sales amount across all locations and dates.  Select all columns (`*`) from the CTE.  This query returns the mean value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `select_all_above_average_sales`\n",
    "\n",
    "Write the same CTE to calculate the `average_sales` number, but this time select only those rows that have an `amount` greater than this average value.  Following the CTE we can still write a select from the `sales` table and return the values that are above the average sales figure using a subquery which selects the average from `average_sales`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Advanced CTEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Records-R-Sweet discovered a bug in its data entry program!  Several rows have been entered into the table multiple times by accident, so the queries from Part 1 might be calculating an incorrect average sale value.  In the `part_2_ctes.py` file, write a query that will delete these duplicate rows.\n",
    "\n",
    "* `cte_deletes_duplicates`\n",
    "\n",
    "Write a CTE that determines the MIN(id), aliased as `minimum_id`, for each `sale_id` from the table.  Then use the `DELETE FROM` clause to remove the rows with id values that are not found in the CTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `correct_above_avg_sales`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much like `select_all_above_average_sales` from Part 1, write a query that returns the above average sales.  However, it is difficult to remember which `location_id` matches with which city.  Add a join statement so that the query returns the city's name, the date of the sale, and the sales amount for only those above average sales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
